{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'E:/Jupyter NB/10 class Classification/Images'\n",
    "\n",
    "image_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test'\n",
    "\n",
    "train_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/train'\n",
    "val_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/val'\n",
    "test_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 33, 33, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 17,023,690\n",
      "Trainable params: 17,023,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(299, 299, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1233 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras import backend as K\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    entropy = -K.mean(K.sum(y_pred*K.log(y_pred), 1))\n",
    "    beta = 0.1\n",
    "    return logloss(y_true, y_pred) - beta*entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss=loss,\n",
    "    optimizer=optimizers.SGD(lr=1e-2),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 49s 491ms/step - loss: 1.9766 - categorical_crossentropy: 2.2008 - accuracy: 0.2403 - val_loss: 2.0199 - val_categorical_crossentropy: 2.2223 - val_accuracy: 0.2350\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 1.7385 - categorical_crossentropy: 1.9444 - accuracy: 0.3441 - val_loss: 1.4286 - val_categorical_crossentropy: 1.8663 - val_accuracy: 0.3400\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 35s 346ms/step - loss: 1.5356 - categorical_crossentropy: 1.7219 - accuracy: 0.4451 - val_loss: 2.0160 - val_categorical_crossentropy: 1.9411 - val_accuracy: 0.3450\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 34s 341ms/step - loss: 1.3874 - categorical_crossentropy: 1.5589 - accuracy: 0.4937 - val_loss: 1.3800 - val_categorical_crossentropy: 1.6186 - val_accuracy: 0.4650\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 34s 344ms/step - loss: 1.2684 - categorical_crossentropy: 1.4285 - accuracy: 0.5368 - val_loss: 1.3622 - val_categorical_crossentropy: 1.5082 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 35s 346ms/step - loss: 1.1326 - categorical_crossentropy: 1.2796 - accuracy: 0.5937 - val_loss: 1.1679 - val_categorical_crossentropy: 1.3765 - val_accuracy: 0.5800\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 34s 341ms/step - loss: 0.9606 - categorical_crossentropy: 1.0898 - accuracy: 0.6588 - val_loss: 1.3467 - val_categorical_crossentropy: 1.4870 - val_accuracy: 0.5350\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 35s 347ms/step - loss: 0.8038 - categorical_crossentropy: 0.9204 - accuracy: 0.7064 - val_loss: 1.3587 - val_categorical_crossentropy: 1.5105 - val_accuracy: 0.5600\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 42s 418ms/step - loss: 0.6075 - categorical_crossentropy: 0.6982 - accuracy: 0.7905 - val_loss: 1.2490 - val_categorical_crossentropy: 1.4322 - val_accuracy: 0.5950\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 58s 580ms/step - loss: 0.4288 - categorical_crossentropy: 0.5031 - accuracy: 0.8570 - val_loss: 2.3664 - val_categorical_crossentropy: 1.6508 - val_accuracy: 0.6050\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4539083242416382, 1.851881504058838, 0.4950000047683716]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('teacher_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 197ms/step\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 6s 100ms/step\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP_SIZE_TEST=train_generator.n//train_generator.batch_size\n",
    "train_generator.reset()\n",
    "pred=model.predict_generator(train_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# remove softmax\n",
    "model.layers.pop()\n",
    "model = Model(model.input, model.layers[-1].output)\n",
    "# now model outputs logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 299, 299, 3)\n",
      "(20, 10)\n",
      "[3.70864844e-04 3.08667404e-06 9.89612639e-01 5.03740180e-03\n",
      " 2.01689458e-04 9.50726331e-04 1.06929794e-04 1.39943499e-03\n",
      " 2.21049669e-03 1.06748725e-04]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1.2886509e-02 1.0360724e-02 6.8904728e-02 1.8360894e-02 5.8740536e-03\n",
      " 1.2576629e-02 7.5834996e-01 1.8690531e-04 1.9583262e-03 1.1054129e-01]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[3.4284876e-06 1.4483948e-03 9.8794252e-01 7.2967913e-03 2.3657728e-04\n",
      " 8.4779695e-06 2.2480544e-04 1.2964559e-03 1.3486993e-03 1.9384523e-04]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[6.4133684e-04 3.4523496e-04 4.2557633e-01 5.7096785e-01 1.2763745e-04\n",
      " 7.5503206e-04 5.5961701e-04 3.9172155e-04 4.0751538e-04 2.2770009e-04]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0.79164964 0.00844734 0.00947156 0.02556248 0.03335799 0.03047122\n",
      " 0.01003691 0.02287291 0.036985   0.03114498]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[2.6692247e-03 7.4775526e-05 3.8005976e-04 3.9239801e-03 9.8496282e-01\n",
      " 3.4750028e-06 7.4976543e-03 4.4595698e-04 3.8789665e-05 3.2318726e-06]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0.00916545 0.06160722 0.1086817  0.05192102 0.1495321  0.00706223\n",
      " 0.01609245 0.04491689 0.52388376 0.02713715]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[9.7406490e-05 8.9364670e-07 2.1305319e-02 9.7654474e-01 6.8660243e-06\n",
      " 1.7122563e-03 6.0983679e-05 6.8659201e-06 1.7433212e-04 9.0351015e-05]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[8.37420486e-03 2.67495937e-03 1.36832185e-02 9.07752663e-03\n",
      " 9.12146747e-01 2.80772522e-03 2.69858297e-02 1.97999123e-02\n",
      " 3.99047416e-03 4.59384813e-04]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[5.9918594e-04 3.3707861e-03 1.6152176e-01 1.1389940e-03 5.5794290e-04\n",
      " 8.2162449e-05 1.2928518e-04 8.2970101e-01 6.7684927e-04 2.2220828e-03]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[2.1604169e-04 2.4972524e-04 2.8537631e-02 4.6767768e-02 8.6521041e-01\n",
      " 8.7126310e-04 6.0938025e-04 4.2508531e-02 1.4457386e-02 5.7184155e-04]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1.5195570e-04 1.8518860e-03 7.9868827e-03 1.1907043e-01 3.8530901e-03\n",
      " 5.6076940e-05 1.0878649e-03 2.1093365e-05 1.5625617e-03 8.6435807e-01]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[4.8508332e-03 9.8579848e-01 5.1339972e-04 1.5944528e-04 8.9752059e-05\n",
      " 1.1530394e-03 4.5686433e-04 5.9201258e-05 6.8940232e-03 2.4817793e-05]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.02038235 0.10183586 0.33819714 0.07878656 0.08088236 0.04318343\n",
      " 0.03000677 0.04696907 0.09578366 0.16397281]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[2.1321375e-04 4.2984600e-04 3.3403872e-04 1.3849389e-02 6.4455541e-03\n",
      " 9.7744751e-01 1.0440632e-05 3.1285341e-05 4.0722627e-04 8.3148136e-04]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0.0068433  0.01412156 0.7223751  0.01438436 0.00266063 0.00591993\n",
      " 0.00192754 0.22159323 0.00430523 0.0058692 ]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1.5249630e-03 1.9602026e-03 1.8854679e-04 9.5546201e-02 8.5793823e-01\n",
      " 4.8978128e-03 2.0860065e-02 3.5264911e-03 1.2676663e-02 8.8083232e-04]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0.02550744 0.00154235 0.10029315 0.79148453 0.01522314 0.01622102\n",
      " 0.03755806 0.00455792 0.00530452 0.00230796]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[9.6098113e-01 2.8281458e-04 8.4121441e-03 1.1434810e-02 7.2890929e-05\n",
      " 3.4456069e-05 2.2292014e-03 2.5222089e-05 1.6403668e-02 1.2367868e-04]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.00970263 0.05084415 0.5011497  0.06379739 0.00943646 0.01146631\n",
      " 0.00819095 0.22113627 0.05736437 0.06691182]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0b588ce40c51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print(train_logits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#print(batch_logits[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtrain_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "batches = 0\n",
    "train_logits = {}\n",
    "\n",
    "for x_batch, name_batch in tqdm(train_generator):\n",
    "    print(np.shape(x_batch))\n",
    "    #print(name_batch)\n",
    "    #print(len(x_batch))\n",
    "    #print(x_batch)\n",
    "    \n",
    "    batch_logits = model.predict_on_batch(x_batch)\n",
    "    print(np.shape(batch_logits))\n",
    "    #print(batch_logits)\n",
    "    for i, n in enumerate(name_batch):\n",
    "        print(batch_logits[i])\n",
    "        print(n)\n",
    "    \n",
    "    for i, n in enumerate(name_batch):\n",
    "        #print(i)\n",
    "        #print(n)\n",
    "        #print(train_logits)\n",
    "        #print(batch_logits[i])\n",
    "        train_logits[n] = batch_logits[i]\n",
    "    '''\n",
    "    batches += 1\n",
    "    if batches >= 400: # 25600/64\n",
    "        break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
