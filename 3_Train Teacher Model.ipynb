{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.0\n",
    "    x -= 0.5\n",
    "    x *= 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/train'\n",
    "val_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/val'\n",
    "#test_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 33, 33, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 17,028,820\n",
      "Trainable params: 17,028,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(299, 299, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 20 classes.\n",
      "Found 400 images belonging to 20 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_generator = data_generator.flow_from_directory(\\n    test_dir,\\n    target_size=(299, 299),\\n    batch_size=20,\\n    shuffle=False)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "'''\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=30, \n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.001,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "'''\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    shuffle=False)\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    shuffle=False)\n",
    "\n",
    "'''\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras import backend as K\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    entropy = -K.mean(K.sum(y_pred*K.log(y_pred), 1))\n",
    "    beta = 0.1\n",
    "    return logloss(y_true, y_pred) - beta*entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss=loss,\n",
    "    optimizer=optimizers.SGD(lr=1e-2),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "118/118 [==============================] - 41s 350ms/step - loss: 2.7227 - categorical_crossentropy: 3.0216 - accuracy: 0.0284 - val_loss: 2.6981 - val_categorical_crossentropy: 2.9848 - val_accuracy: 0.0867\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.6796 - categorical_crossentropy: 2.9783 - accuracy: 0.0746 - val_loss: 2.1257 - val_categorical_crossentropy: 2.9115 - val_accuracy: 0.1383\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - 67s 570ms/step - loss: 2.6679 - categorical_crossentropy: 2.9646 - accuracy: 0.0822 - val_loss: 2.3772 - val_categorical_crossentropy: 2.8481 - val_accuracy: 0.1083\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - 77s 653ms/step - loss: 2.5928 - categorical_crossentropy: 2.8826 - accuracy: 0.1254 - val_loss: 2.6003 - val_categorical_crossentropy: 2.7553 - val_accuracy: 0.1517\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 2.5449 - categorical_crossentropy: 2.8303 - accuracy: 0.1267 - val_loss: 2.1251 - val_categorical_crossentropy: 2.7591 - val_accuracy: 0.1483\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.4609 - categorical_crossentropy: 2.7396 - accuracy: 0.1661 - val_loss: 2.4161 - val_categorical_crossentropy: 2.5717 - val_accuracy: 0.2433\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.3616 - categorical_crossentropy: 2.6300 - accuracy: 0.2034 - val_loss: 2.4759 - val_categorical_crossentropy: 2.6811 - val_accuracy: 0.1783\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 2.3418 - categorical_crossentropy: 2.6096 - accuracy: 0.2004 - val_loss: 2.2938 - val_categorical_crossentropy: 2.5181 - val_accuracy: 0.2417\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.2175 - categorical_crossentropy: 2.4715 - accuracy: 0.2424 - val_loss: 2.7208 - val_categorical_crossentropy: 2.6569 - val_accuracy: 0.2067\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.1951 - categorical_crossentropy: 2.4496 - accuracy: 0.2466 - val_loss: 2.2481 - val_categorical_crossentropy: 2.4231 - val_accuracy: 0.2767\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 2.0892 - categorical_crossentropy: 2.3329 - accuracy: 0.3110 - val_loss: 2.5765 - val_categorical_crossentropy: 2.4345 - val_accuracy: 0.3067\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 2.0139 - categorical_crossentropy: 2.2530 - accuracy: 0.3106 - val_loss: 2.0716 - val_categorical_crossentropy: 2.3938 - val_accuracy: 0.3083\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 1.8439 - categorical_crossentropy: 2.0685 - accuracy: 0.3763 - val_loss: 2.5882 - val_categorical_crossentropy: 2.4386 - val_accuracy: 0.2500\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 1.7161 - categorical_crossentropy: 1.9292 - accuracy: 0.3928 - val_loss: 2.1398 - val_categorical_crossentropy: 2.4020 - val_accuracy: 0.2983\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 1.5189 - categorical_crossentropy: 1.7110 - accuracy: 0.4835 - val_loss: 2.4608 - val_categorical_crossentropy: 2.4206 - val_accuracy: 0.2683\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 1.3770 - categorical_crossentropy: 1.5588 - accuracy: 0.5229 - val_loss: 2.2620 - val_categorical_crossentropy: 2.3937 - val_accuracy: 0.3533\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 1.0452 - categorical_crossentropy: 1.1945 - accuracy: 0.6398 - val_loss: 2.7865 - val_categorical_crossentropy: 2.7329 - val_accuracy: 0.3083\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.7433 - categorical_crossentropy: 0.8603 - accuracy: 0.7525 - val_loss: 3.7200 - val_categorical_crossentropy: 3.3155 - val_accuracy: 0.2600\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.8512 - categorical_crossentropy: 0.9664 - accuracy: 0.7284 - val_loss: 3.2162 - val_categorical_crossentropy: 2.8775 - val_accuracy: 0.2450\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.4768 - categorical_crossentropy: 0.5622 - accuracy: 0.8597 - val_loss: 3.2298 - val_categorical_crossentropy: 2.6876 - val_accuracy: 0.4167\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.1452 - categorical_crossentropy: 0.1831 - accuracy: 0.9597 - val_loss: 3.1769 - val_categorical_crossentropy: 3.5111 - val_accuracy: 0.3400\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.0620 - categorical_crossentropy: 0.0805 - accuracy: 0.9860 - val_loss: 3.7684 - val_categorical_crossentropy: 3.4204 - val_accuracy: 0.4067\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0778 - categorical_crossentropy: 0.0939 - accuracy: 0.9860 - val_loss: 4.7599 - val_categorical_crossentropy: 3.8341 - val_accuracy: 0.3433\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0160 - categorical_crossentropy: 0.0248 - accuracy: 0.9962 - val_loss: 4.2442 - val_categorical_crossentropy: 3.7424 - val_accuracy: 0.3917\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0122 - categorical_crossentropy: 0.0183 - accuracy: 0.9962 - val_loss: 4.4501 - val_categorical_crossentropy: 4.2109 - val_accuracy: 0.3567\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0071 - categorical_crossentropy: 0.0118 - accuracy: 0.9987 - val_loss: 4.5857 - val_categorical_crossentropy: 3.9777 - val_accuracy: 0.3967\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0068 - categorical_crossentropy: 0.0108 - accuracy: 0.9975 - val_loss: 4.9220 - val_categorical_crossentropy: 4.4998 - val_accuracy: 0.3550\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0068 - categorical_crossentropy: 0.0104 - accuracy: 0.9975 - val_loss: 4.7398 - val_categorical_crossentropy: 4.0957 - val_accuracy: 0.4017\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0072 - categorical_crossentropy: 0.0105 - accuracy: 0.9970 - val_loss: 3.9721 - val_categorical_crossentropy: 4.5293 - val_accuracy: 0.3533\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - 67s 568ms/step - loss: 0.0030 - categorical_crossentropy: 0.0056 - accuracy: 0.9992 - val_loss: 4.8135 - val_categorical_crossentropy: 4.2804 - val_accuracy: 0.4050\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0052 - categorical_crossentropy: 0.0080 - accuracy: 0.9979 - val_loss: 5.0652 - val_categorical_crossentropy: 4.8430 - val_accuracy: 0.3600\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0045 - categorical_crossentropy: 0.0070 - accuracy: 0.9979 - val_loss: 5.1602 - val_categorical_crossentropy: 4.3769 - val_accuracy: 0.4050\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - 78s 657ms/step - loss: 0.0034 - categorical_crossentropy: 0.0055 - accuracy: 0.9983 - val_loss: 5.3659 - val_categorical_crossentropy: 4.9397 - val_accuracy: 0.3600\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - 67s 568ms/step - loss: 0.0031 - categorical_crossentropy: 0.0050 - accuracy: 0.9992 - val_loss: 5.2152 - val_categorical_crossentropy: 4.5019 - val_accuracy: 0.4117\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0032 - categorical_crossentropy: 0.0051 - accuracy: 0.9979 - val_loss: 4.6992 - val_categorical_crossentropy: 4.9283 - val_accuracy: 0.3600\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - 67s 565ms/step - loss: 0.0044 - categorical_crossentropy: 0.0065 - accuracy: 0.9987 - val_loss: 5.1682 - val_categorical_crossentropy: 4.5746 - val_accuracy: 0.4133\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.0034 - categorical_crossentropy: 0.0053 - accuracy: 0.9983 - val_loss: 5.1716 - val_categorical_crossentropy: 5.0627 - val_accuracy: 0.3583\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0027 - categorical_crossentropy: 0.0044 - accuracy: 0.9987 - val_loss: 5.3607 - val_categorical_crossentropy: 4.6208 - val_accuracy: 0.4050\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - 67s 567ms/step - loss: 0.0023 - categorical_crossentropy: 0.0037 - accuracy: 0.9987 - val_loss: 5.4232 - val_categorical_crossentropy: 5.1535 - val_accuracy: 0.3617\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - 67s 566ms/step - loss: 0.0023 - categorical_crossentropy: 0.0039 - accuracy: 0.9987 - val_loss: 5.3458 - val_categorical_crossentropy: 4.6893 - val_accuracy: 0.4100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=118,\n",
    "    epochs=40,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('teacher_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size\\ntest_generator.reset()\\npred=model.predict_generator(test_generator,\\nsteps=STEP_SIZE_TEST,\\nverbose=1)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSTEP_SIZE_TEST=train_generator.n//train_generator.batch_size\\ntrain_generator.reset()\\npred=model.predict_generator(train_generator,\\n    steps=STEP_SIZE_TEST,\\n    verbose=1)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEP_SIZE_TEST=train_generator.n//train_generator.batch_size\n",
    "train_generator.reset()\n",
    "pred=model.predict_generator(train_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
