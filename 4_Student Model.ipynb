{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'E:/Jupyter NB/10 class Classification/'\n",
    "\n",
    "train_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/train'\n",
    "val_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/val'\n",
    "test_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, concatenate, Activation\n",
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.0\n",
    "    x -= 0.5\n",
    "    x *= 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 297, 297, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 148, 148, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 146, 146, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 170528)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                10913856  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1300      \n",
      "=================================================================\n",
      "Total params: 10,920,244\n",
      "Trainable params: 10,920,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "std_model = models.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (299,299,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(20, activation = 'softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "std_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 20 classes.\n",
      "Found 400 images belonging to 20 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_generator = data_generator.flow_from_directory(\\n    test_dir,\\n    target_size=(299, 299),\\n    batch_size=20)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(data_format='channels_last', preprocessing_function = preprocess_input)\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    shuffle=False)\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    shuffle=False)\n",
    "\n",
    "'''\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    entropy = -K.mean(K.sum(y_pred*K.log(y_pred), 1))\n",
    "    beta = 0.1\n",
    "    return logloss(y_true, y_pred) - beta*entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "std_model.compile(loss=loss,\n",
    "    optimizer=optimizers.SGD(lr=1e-3),\n",
    "    metrics=['categorical_crossentropy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 2.7263 - categorical_crossentropy: 3.0249 - accuracy: 0.0313 - val_loss: 2.6976 - val_categorical_crossentropy: 2.9958 - val_accuracy: 0.0575\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 23s 154ms/step - loss: 2.7024 - categorical_crossentropy: 3.0015 - accuracy: 0.0443 - val_loss: 2.8237 - val_categorical_crossentropy: 3.0227 - val_accuracy: 0.0525\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 2.7095 - categorical_crossentropy: 3.0072 - accuracy: 0.0593 - val_loss: 2.7331 - val_categorical_crossentropy: 2.9689 - val_accuracy: 0.0425\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 2.6552 - categorical_crossentropy: 2.9490 - accuracy: 0.0907 - val_loss: 2.9079 - val_categorical_crossentropy: 2.9063 - val_accuracy: 0.0850\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 2.6130 - categorical_crossentropy: 2.9042 - accuracy: 0.1163 - val_loss: 2.9948 - val_categorical_crossentropy: 2.8824 - val_accuracy: 0.0800\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 34s 224ms/step - loss: 2.5870 - categorical_crossentropy: 2.8771 - accuracy: 0.1090 - val_loss: 2.8102 - val_categorical_crossentropy: 2.8485 - val_accuracy: 0.1350\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 38s 254ms/step - loss: 2.5103 - categorical_crossentropy: 2.7969 - accuracy: 0.1440 - val_loss: 2.9476 - val_categorical_crossentropy: 2.7921 - val_accuracy: 0.1175\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 38s 256ms/step - loss: 2.5107 - categorical_crossentropy: 2.7953 - accuracy: 0.1340 - val_loss: 2.6343 - val_categorical_crossentropy: 2.7833 - val_accuracy: 0.1525\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 38s 255ms/step - loss: 2.4170 - categorical_crossentropy: 2.6968 - accuracy: 0.1770 - val_loss: 2.8754 - val_categorical_crossentropy: 2.7277 - val_accuracy: 0.1550\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 38s 254ms/step - loss: 2.4039 - categorical_crossentropy: 2.6821 - accuracy: 0.1717 - val_loss: 1.9427 - val_categorical_crossentropy: 2.7363 - val_accuracy: 0.2125\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 38s 254ms/step - loss: 2.3378 - categorical_crossentropy: 2.6105 - accuracy: 0.2067 - val_loss: 2.6326 - val_categorical_crossentropy: 2.6688 - val_accuracy: 0.1950\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 38s 255ms/step - loss: 2.2709 - categorical_crossentropy: 2.5401 - accuracy: 0.2313 - val_loss: 2.7450 - val_categorical_crossentropy: 2.7549 - val_accuracy: 0.1400\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 38s 254ms/step - loss: 2.2168 - categorical_crossentropy: 2.4795 - accuracy: 0.2567 - val_loss: 2.3908 - val_categorical_crossentropy: 2.6050 - val_accuracy: 0.2075\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 38s 254ms/step - loss: 2.1557 - categorical_crossentropy: 2.4165 - accuracy: 0.2653 - val_loss: 3.0789 - val_categorical_crossentropy: 2.6279 - val_accuracy: 0.2075\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 39s 258ms/step - loss: 2.0840 - categorical_crossentropy: 2.3368 - accuracy: 0.3033 - val_loss: 2.2421 - val_categorical_crossentropy: 2.5799 - val_accuracy: 0.2250\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 2.0378 - categorical_crossentropy: 2.2907 - accuracy: 0.3160 - val_loss: 1.8410 - val_categorical_crossentropy: 2.7111 - val_accuracy: 0.1850\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 1.9364 - categorical_crossentropy: 2.1792 - accuracy: 0.3670 - val_loss: 1.7100 - val_categorical_crossentropy: 2.5124 - val_accuracy: 0.2900\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 38s 256ms/step - loss: 1.9031 - categorical_crossentropy: 2.1443 - accuracy: 0.3610 - val_loss: 1.4835 - val_categorical_crossentropy: 2.6395 - val_accuracy: 0.2325\n",
      "Epoch 19/20\n",
      "105/150 [====================>.........] - ETA: 10s - loss: 1.8206 - categorical_crossentropy: 2.0564 - accuracy: 0.3995"
     ]
    }
   ],
   "source": [
    "history = std_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=150,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
