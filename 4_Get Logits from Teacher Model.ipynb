{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from keras import models\n",
    "from keras import layers\n",
    "sys.path.append('utils/')\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/train'\n",
    "val_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/val'\n",
    "test_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1233 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x0000020279250F48>\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 33, 33, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 17,023,690\n",
      "Trainable params: 17,023,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(299, 299, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights('teacher_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove softmax\n",
    "model.layers.pop()\n",
    "model = Model(model.input, model.layers[-1].output)\n",
    "# now model outputs logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 299, 299, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/62 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10)\n",
      "[9.9999404e-01 4.6660030e-06 6.1792473e-09 1.7965229e-08 5.5401091e-07\n",
      " 1.1006326e-13 5.8776681e-07 1.0414213e-11 8.1122067e-08 1.3741929e-12]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[2.5648283e-04 2.1063967e-03 5.1945648e-05 4.7695744e-07 5.8945457e-08\n",
      " 3.7551521e-11 2.2951220e-07 9.9756819e-01 1.4652124e-05 1.6847829e-06]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[6.1069396e-03 1.5808641e-03 1.1079933e-02 9.7151542e-01 3.0115894e-03\n",
      " 1.0576836e-03 8.4964046e-04 5.3919513e-05 3.6088272e-03 1.1352485e-03]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1.2698478e-08 1.5972486e-04 9.9978071e-01 2.2829943e-06 7.2422329e-10\n",
      " 5.8703620e-08 1.0723579e-05 4.6174282e-05 3.2977377e-07 1.7632200e-09]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1.1793785e-05 5.1060006e-06 9.9559021e-01 7.4108408e-07 8.4767350e-07\n",
      " 8.2210983e-07 1.7488235e-06 4.1704443e-03 2.1830961e-04 1.2741569e-07]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[4.9386449e-07 1.1084245e-04 1.0550124e-06 3.8726392e-04 9.2518756e-05\n",
      " 9.9810696e-01 5.7433205e-09 5.1701656e-05 7.2761573e-04 5.2142452e-04]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[2.9863528e-10 2.4288423e-04 1.3052036e-04 2.4549032e-04 9.9900764e-01\n",
      " 7.4483701e-06 1.1709637e-04 1.9515261e-05 2.2904265e-04 2.7068893e-07]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[3.3270734e-04 3.6154085e-04 6.9964379e-03 1.0062887e-03 3.3925904e-04\n",
      " 9.8193294e-01 1.7814275e-03 7.5554679e-05 6.9977092e-03 1.7615473e-04]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[2.7190681e-09 1.5331804e-06 9.1247528e-04 2.4911546e-06 1.4341273e-04\n",
      " 9.9892873e-01 9.1736787e-09 2.5348648e-10 1.1481550e-05 7.2280987e-11]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[6.4276968e-04 2.3673429e-08 1.1130334e-05 5.0244977e-09 2.7704627e-07\n",
      " 3.0883449e-12 6.1064893e-05 1.4411745e-09 9.9928480e-01 5.1369120e-10]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[5.8798410e-04 2.1582044e-07 8.2387021e-07 1.4797913e-05 9.9906367e-01\n",
      " 4.5812433e-15 1.5699221e-05 2.1197473e-11 1.0767404e-05 3.0599080e-04]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[4.2268380e-10 1.5008685e-07 7.5554931e-09 1.3329421e-09 9.1809966e-08\n",
      " 9.0407870e-10 3.9611482e-06 1.0820244e-16 9.9999583e-01 2.3495112e-12]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[1.8276963e-11 6.9570408e-05 3.9654331e-08 5.9935588e-05 9.9983442e-01\n",
      " 1.4547413e-05 1.4700559e-05 1.0500801e-06 5.4863804e-06 2.4872443e-07]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1.2825448e-10 6.0151012e-07 1.8788166e-06 9.9935120e-01 6.3955993e-04\n",
      " 4.0813178e-10 2.7910008e-09 6.6018215e-06 1.2518488e-07 1.5198217e-09]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[5.3293991e-08 4.0476421e-05 5.2487821e-04 4.6594896e-06 4.0358604e-08\n",
      " 3.0504529e-05 1.9217848e-06 2.6870865e-04 9.9912876e-01 2.5471650e-10]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[7.33634952e-05 5.53545251e-04 2.42348483e-06 1.40701974e-04\n",
      " 9.86745179e-01 1.59116553e-05 1.89375733e-05 1.24382395e-02\n",
      " 1.08210543e-05 9.04079911e-07]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1.3555624e-04 1.8302980e-04 3.4446411e-02 2.1552118e-03 2.3179140e-04\n",
      " 1.8137731e-06 2.3410603e-06 7.3787215e-04 9.6209985e-01 6.1878686e-06]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[6.6335865e-08 1.3289899e-05 8.1606577e-06 5.8632554e-06 5.6867571e-05\n",
      " 1.7249621e-07 3.5227504e-07 3.2830647e-10 9.8798309e-06 9.9990535e-01]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[3.7616482e-07 6.5744634e-06 1.6000847e-04 3.1130089e-04 7.0286865e-06\n",
      " 1.5570446e-07 1.1263886e-06 1.0970050e-06 9.9951208e-01 2.6265747e-07]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[3.9449043e-04 1.7954782e-05 4.3798543e-08 7.3590165e-09 9.9017733e-01\n",
      " 2.8347981e-07 9.3418732e-03 6.3723506e-05 4.2021748e-06 5.0741127e-09]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9ea827945116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print(train_logits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#print(batch_logits[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtrain_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     '''\n\u001b[0;32m     27\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "batches = 0\n",
    "train_logits = {}\n",
    "\n",
    "for x_batch, name_batch in tqdm(train_generator):\n",
    "    #print(np.shape(x_batch))\n",
    "    #print(name_batch)\n",
    "    #print(len(x_batch))\n",
    "    #print(x_batch)\n",
    "    \n",
    "    batch_logits = model.predict_on_batch(x_batch)\n",
    "    \n",
    "    '''\n",
    "    # Checking\n",
    "    \n",
    "    print(np.shape(batch_logits))\n",
    "    #print(batch_logits)\n",
    "    for i, n in enumerate(name_batch):\n",
    "        print(batch_logits[i])\n",
    "        print(n)\n",
    "    '''\n",
    "    \n",
    "    for i, n in enumerate(name_batch):\n",
    "        #print(i)\n",
    "        #print(n)\n",
    "        #print(train_logits)\n",
    "        #print(batch_logits[i])\n",
    "        train_logits[n] = batch_logits[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
