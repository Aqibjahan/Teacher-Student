{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder for images\n",
    "dir_train = 'E:/Jupyter NB/10 class Classification/Images'\n",
    "\n",
    "# the directory of separeated images\n",
    "image_dir = 'E:/Jupyter NB/10 class Classification/Train_val_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This cell is for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor root, dirs, files in os.walk(dir_train):\\n    print('---root---')\\n    print(root)\\n    print('---dirs---')\\n    print(dirs)\\n    print('---files---')\\n    print(files)\\n    print('---------------------')\\n\\n\\n\\nsubdirs = list(os.walk(dir_train))[1:]\\n\\nfor dir_path, _, files in tqdm(subdirs):\\n    \\n    dir_name = dir_path.split('\\\\')[-1]\\n    print(dir_name)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for root, dirs, files in os.walk(dir_train):\n",
    "    print('---root---')\n",
    "    print(root)\n",
    "    print('---dirs---')\n",
    "    print(dirs)\n",
    "    print('---files---')\n",
    "    print(files)\n",
    "    print('---------------------')\n",
    "\n",
    "\n",
    "\n",
    "subdirs = list(os.walk(dir_train))[1:]\n",
    "\n",
    "for dir_path, _, files in tqdm(subdirs):\n",
    "    \n",
    "    dir_name = dir_path.split('\\\\')[-1]\n",
    "    print(dir_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]C:\\Users\\aRnob\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "subdirs = list(os.walk(dir_train))[1:]\n",
    "\n",
    "# collect train metadata\n",
    "train_metadata = []\n",
    "\n",
    "for dir_path, _, files in tqdm(subdirs):\n",
    "    \n",
    "    dir_name = dir_path.split('\\\\')[-1]\n",
    "    \n",
    "    for file_name in files:\n",
    "        if not file_name.startswith('.'):\n",
    "            # read image\n",
    "            temp = misc.imread(os.path.join(dir_path, file_name)) \n",
    "            # collect image metadata\n",
    "            image_metadata = []\n",
    "            image_metadata.extend([dir_name, file_name])\n",
    "            image_metadata.extend( \n",
    "                list(temp.shape) if len(temp.shape) == 3 \n",
    "                else [temp.shape[0], temp.shape[1], 1]\n",
    "            )\n",
    "            image_metadata.extend([temp.nbytes, temp.dtype])\n",
    "            # append image metadata to list\n",
    "            train_metadata.append(image_metadata)\n",
    "\n",
    "#print(train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.DataFrame(train_metadata)\n",
    "M.columns = ['directory', 'img_name', 'height', 'width', 'channels', 'byte_size', 'bit_depth']\n",
    "\n",
    "M['category_name'] = M.directory.apply(lambda x: x.split('.')[-1].lower())\n",
    "M['img_extension'] = M.img_name.apply(lambda x: x.split('.')[-1])\n",
    "M['category_number'] = M.directory.apply(lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of grayscale images\n",
    "(M.channels != 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of categories\n",
    "M.category_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class number -> class name\n",
    "decode = {n: i for i, n in M.groupby('category_name').category_number.first().iteritems()}\n",
    "decode\n",
    "\n",
    "np.save('decode.npy', decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 20 images per class for test\\nTest = M.groupby('category_name', group_keys=False).apply(lambda x: x.sample(n=20, replace=False))\\nTest.sort_index(inplace=True)\\nM.drop(Test.index, axis=0, inplace=True)\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 images per class\n",
    "V = M.groupby('category_name', group_keys=False).apply(lambda x: x.sample(n=20, replace=False))\n",
    "V.sort_index(inplace=True)\n",
    "M.drop(V.index, axis=0, inplace=True)\n",
    "\n",
    "'''\n",
    "# 20 images per class for test\n",
    "Test = M.groupby('category_name', group_keys=False).apply(lambda x: x.sample(n=20, replace=False))\n",
    "Test.sort_index(inplace=True)\n",
    "M.drop(Test.index, axis=0, inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data\n",
    "len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "#len(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.to_csv('train_metadata.csv', index=False)\n",
    "V.to_csv('val_metadata.csv', index=False)\n",
    "#Test.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('E:/Jupyter NB/10 class Classification/train_metadata.csv')\n",
    "v = pd.read_csv('E:/Jupyter NB/10 class Classification/val_metadata.csv')\n",
    "#test = pd.read_csv('E:/Jupyter NB/10 class Classification/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(image_dir + '/train_no_resizing')\n",
    "for i in range(1, 20 + 1):\n",
    "    os.mkdir(image_dir + '/train_no_resizing/' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(image_dir + '/val_no_resizing')\n",
    "for i in range(1, 20 + 1):\n",
    "    os.mkdir(image_dir + '/val_no_resizing/' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nos.mkdir(image_dir + '/test_no_resizing')\\nfor i in range(1, 20 + 1):\\n    os.mkdir(image_dir + '/test_no_resizing/' + str(i))\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "os.mkdir(image_dir + '/test_no_resizing')\n",
    "for i in range(1, 20 + 1):\n",
    "    os.mkdir(image_dir + '/test_no_resizing/' + str(i))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(t)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2347it [00:14, 158.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# RGB images\n",
    "for i, row in tqdm(t.loc[t.channels == 3].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'train_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# grayscale images\n",
    "for i, row in tqdm(t.loc[t.channels == 1].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # convert to RGB\n",
    "    array = np.asarray(image, dtype='uint8')\n",
    "    array = np.stack([array, array, array], axis=2)\n",
    "    image = Image.fromarray(array)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'train_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = len(v)\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [00:02, 145.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# RGB images\n",
    "for i, row in tqdm(v.loc[v.channels == 3].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'val_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 101.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# grayscale images\n",
    "for i, row in tqdm(v.loc[v.channels == 1].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # convert to RGB\n",
    "    array = np.asarray(image, dtype='uint8')\n",
    "    array = np.stack([array, array, array], axis=2)\n",
    "    image = Image.fromarray(array)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'val_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_size = len(test)\\ntest_size\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_size = len(test)\n",
    "test_size\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# RGB images\\nfor i, row in tqdm(test.loc[test.channels == 3].iterrows()):\\n    # get image\\n    file_path = os.path.join(dir_train, row.directory, row.img_name)\\n    image = Image.open(file_path)\\n    \\n    # save\\n    save_path = os.path.join(image_dir, 'test_no_resizing', str(row.category_number), row.img_name)\\n    image.save(save_path, 'jpeg')\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# RGB images\n",
    "for i, row in tqdm(test.loc[test.channels == 3].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'test_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# grayscale images\\nfor i, row in tqdm(test.loc[test.channels == 1].iterrows()):\\n    # get image\\n    file_path = os.path.join(dir_train, row.directory, row.img_name)\\n    image = Image.open(file_path)\\n    \\n    # convert to RGB\\n    array = np.asarray(image, dtype='uint8')\\n    array = np.stack([array, array, array], axis=2)\\n    image = Image.fromarray(array)\\n    \\n    # save\\n    save_path = os.path.join(image_dir, 'test_no_resizing', str(row.category_number), row.img_name)\\n    image.save(save_path, 'jpeg')\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# grayscale images\n",
    "for i, row in tqdm(test.loc[test.channels == 1].iterrows()):\n",
    "    # get image\n",
    "    file_path = os.path.join(dir_train, row.directory, row.img_name)\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # convert to RGB\n",
    "    array = np.asarray(image, dtype='uint8')\n",
    "    array = np.stack([array, array, array], axis=2)\n",
    "    image = Image.fromarray(array)\n",
    "    \n",
    "    # save\n",
    "    save_path = os.path.join(image_dir, 'test_no_resizing', str(row.category_number), row.img_name)\n",
    "    image.save(save_path, 'jpeg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
